{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPPBep8EqFBNrVJ5g1+JUGK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peppopi/Piratas/blob/main/Target_66_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Inicie el Drive si lo necesita\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyJIYdRjJPlx",
        "outputId": "df8656a9-795b-447a-fe00-9903da41e07b",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import sqlite3\n",
        "import hashlib\n",
        "import imghdr\n",
        "#@markdown ### Crea el Datastet\n",
        "#@markdown ###  Ruta de la carpeta con los archivos .txt y las imágenes (Formato Standar)\n",
        "dataset_folder = '/content/drive/MyDrive/lora_training/datasets/ampharos' #@param {type:\"string\"}\n",
        "\n",
        "# Ruta de la carpeta del dataset\n",
        "output_folder = 'my_dataset'\n",
        "\n",
        "# Crear la carpeta del dataset si no existe\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Crear la carpeta 'images' dentro del dataset si no existe\n",
        "images_folder = os.path.join(output_folder, 'images')\n",
        "if not os.path.exists(images_folder):\n",
        "    os.makedirs(images_folder)\n",
        "\n",
        "# Conectar a la base de datos\n",
        "conn = sqlite3.connect(os.path.join(output_folder, 'my-dataset.sqlite'))\n",
        "\n",
        "# Crear la tabla 'posts'\n",
        "conn.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS posts (\n",
        "        id INTEGER PRIMARY KEY,\n",
        "        md5 TEXT,\n",
        "        file_ext TEXT,\n",
        "        tag_string TEXT,\n",
        "        tag_count_general INTEGER\n",
        "    )\n",
        "''')\n",
        "\n",
        "# Recorrer los archivos .txt y las imágenes en la carpeta\n",
        "for filename in os.listdir(dataset_folder):\n",
        "    if filename.endswith('.txt'):\n",
        "        # Leer el archivo .txt\n",
        "        with open(os.path.join(dataset_folder, filename), 'r') as file:\n",
        "            # Obtener el nombre de la imagen a partir del nombre del archivo .txt\n",
        "            image_name = os.path.splitext(filename)[0]\n",
        "\n",
        "            # Leer los tags del archivo .txt\n",
        "            tag_string = file.readline().strip()\n",
        "\n",
        "            # Calcular el hash MD5 del nombre de la imagen\n",
        "            md5 = hashlib.md5(image_name.encode()).hexdigest()\n",
        "\n",
        "            # Buscar el archivo de imagen en la carpeta\n",
        "            image_path = None\n",
        "            for root, dirs, files in os.walk(dataset_folder):\n",
        "                for file in files:\n",
        "                    if file.startswith(image_name):\n",
        "                        image_path = os.path.join(root, file)\n",
        "                        break\n",
        "                if image_path:\n",
        "                    break\n",
        "\n",
        "            # Asignar la extensión de archivo utilizando imghdr\n",
        "            image_extension = imghdr.what(image_path)\n",
        "\n",
        "            # Insertar el registro en la tabla 'posts'\n",
        "            conn.execute('INSERT INTO posts (id, md5, file_ext, tag_string, tag_count_general) VALUES (?, ?, ?, ?, ?)',\n",
        "                         (image_name, md5, image_extension, tag_string, len(tag_string.split())))\n",
        "\n",
        "            # Copiar la imagen a la carpeta 'images' del dataset si se encontró la ruta\n",
        "            if image_path:\n",
        "                shutil.copy(image_path, os.path.join(images_folder, f\"{image_name}.{image_extension}\"))\n",
        "            else:\n",
        "                print(f\"No se encontró la imagen para {image_name}\")\n",
        "\n",
        "\n",
        "# Cerrar la conexión a la base de datos\n",
        "conn.commit()\n",
        "conn.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "II-Mb5xpOK3u",
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YldvavFoF2es",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Entrena Tu Chekpoint\n",
        "##Saca Advertencias\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "##\n",
        "import os\n",
        "\n",
        "# Instalar las dependencias con pip en modo silencioso\n",
        "!pip install -qq tensorflow tensorflow-io Click numpy requests scikit-image six\n",
        "\n",
        "# Descargar el repositorio de DeepDanbooru desde GitHub\n",
        "!git clone -q https://github.com/KichangKim/DeepDanbooru\n",
        "\n",
        "# Acceder a la carpeta de DeepDanbooru\n",
        "%cd DeepDanbooru\n",
        "\n",
        "# Instalar DeepDanbooru junto con TensorFlow en modo silencioso\n",
        "!pip install -qq .[tensorflow]\n",
        "\n",
        "# Crear un proyecto en DeepDanbooru\n",
        "!deepdanbooru create-project my_project\n",
        "\n",
        "\n",
        "import requests\n",
        "import os\n",
        "\n",
        "# URL del archivo tags.txt\n",
        "url = 'https://github.com/peppopi/Piratas/raw/main/tags.txt'\n",
        "\n",
        "# Ruta de destino para guardar el archivo\n",
        "destination_folder = '/content/DeepDanbooru/my_project'\n",
        "\n",
        "# Nombre de archivo para guardar el archivo descargado\n",
        "filename = 'tags.txt'\n",
        "\n",
        "# Ruta completa del archivo de destino\n",
        "destination_path = os.path.join(destination_folder, filename)\n",
        "\n",
        "# Descargar el archivo\n",
        "response = requests.get(url)\n",
        "if response.status_code == 200:\n",
        "    with open(destination_path, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print('El archivo se ha descargado correctamente.')\n",
        "else:\n",
        "    print('No se pudo descargar el archivo.')\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Ruta del proyecto DeepDanbooru\n",
        "project_folder = '/content/DeepDanbooru/my_project'\n",
        "\n",
        "# Ruta del archivo SQLite\n",
        "sqlite_path = '/content/DeepDanbooru/my_project/my-dataset.sqlite'\n",
        "\n",
        "# Copiar tu dataset a la carpeta del proyecto (reemplaza /ruta/a/tu/dataset por la ruta real de tu dataset)\n",
        "!mkdir -p {os.path.join(project_folder, 'dataset', 'images')}\n",
        "!cp -r /content/my_dataset* {os.path.join(project_folder, 'dataset')}\n",
        "\n",
        "import os\n",
        "\n",
        "source_folder = '/content/DeepDanbooru/my_project/dataset/my_dataset'\n",
        "destination_folder = '/content/DeepDanbooru/my_project'\n",
        "\n",
        "# Mover los archivos y carpetas al destino\n",
        "!mv {source_folder}/* {destination_folder}\n",
        "\n",
        "# Eliminar la carpeta de origen vacía\n",
        "!rm -r {source_folder}\n",
        "\n",
        "# Modificar el archivo project.json en la carpeta del proyecto\n",
        "project_json_path = os.path.join(project_folder, 'project.json')\n",
        "if os.path.exists(project_json_path):\n",
        "    with open(project_json_path, 'r') as f:\n",
        "        project_data = json.load(f)\n",
        "    project_data['database_path'] = sqlite_path\n",
        "    with open(project_json_path, 'w') as f:\n",
        "        json.dump(project_data, f, indent=4)\n",
        "\n",
        "import json\n",
        "\n",
        "# Ruta del archivo project.json\n",
        "project_json_path = '/content/DeepDanbooru/my_project/project.json'\n",
        "\n",
        "# Cargar los datos actuales del archivo project.json\n",
        "with open(project_json_path, 'r') as f:\n",
        "    project_data = json.load(f)\n",
        "\n",
        "# Modificar las características deseadas\n",
        "#@markdown Establece el ancho de las imágenes que se utilizarán durante el entrenamiento y evaluación del modelo\n",
        "project_data['image_width'] = 299 #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Establece el alto de las imágenes que se utilizarán durante el entrenamiento y evaluación del modelo\n",
        "project_data['image_height'] = 299 #@param {type:\"string\"}\n",
        "\n",
        "# Especifica la ruta del archivo de base de datos SQLite que contiene la información de las imágenes y sus etiquetas\n",
        "project_data['database_path'] = '/content/DeepDanbooru/my_project/my-dataset.sqlite'\n",
        "\n",
        "#@markdown Define el recuento mínimo de etiquetas requerido para que una imagen sea considerada en el entrenamiento\n",
        "project_data['minimum_tag_count'] = 20 #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Especifica el modelo que se utilizará para el entrenamiento y evaluación\n",
        "project_data['model'] = 'resnet_custom_v2'  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Establece el tamaño del minibatch utilizado durante el entrenamiento\n",
        "project_data['minibatch_size'] = 32 #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Define la cantidad de epochs (iteraciones completas a través del conjunto de datos) que se realizarán durante el entrenamiento\n",
        "project_data['epoch_count'] = 10 #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Especifica la frecuencia con la que se exportará el modelo durante el entrenamiento\n",
        "project_data['export_model_per_epoch'] = 10 #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Define la frecuencia con la que se guardará un punto de control (checkpoint) del modelo durante el entrenamiento\n",
        "project_data['checkpoint_frequency_mb'] = 200 #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Establece la frecuencia con la que se mostrarán los registros de progreso en la consola durante el entrenamiento\n",
        "project_data['console_logging_frequency_mb'] = 10 #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Especifica la función de pérdida que se utilizará durante el entrenamiento\n",
        "project_data['loss'] = 'binary_crossentropy'  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Define el optimizador que se utilizará para ajustar los pesos del modelo durante el entrenamiento\n",
        "project_data['optimizer'] = 'adam'  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Establece la tasa de aprendizaje del optimizador\n",
        "project_data['learning_rate'] = 0.001 #@param {type:\"string\"}\n",
        "\n",
        "#Define el rango de rotación que se aplicará a las imágenes durante el entrenamiento\n",
        "project_data['rotation_range'] = [0.0, 360.0]\n",
        "\n",
        "# Define el rango de escala que se aplicará a las imágenes durante el entrenamiento\n",
        "project_data['scale_range'] = [0.9, 1.1]\n",
        "\n",
        "# Define el rango de desplazamiento horizontal y vertical que se aplicará a las imágenes durante el entrenamiento\n",
        "project_data['shift_range'] = [-0.1, 0.1]\n",
        "\n",
        "#@markdown Indica si se utilizará la precisión mixta durante el entrenamiento\n",
        "project_data['mixed_precision'] = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "\n",
        "# Guardar los cambios en el archivo project.json\n",
        "with open(project_json_path, 'w') as f:\n",
        "    json.dump(project_data, f, indent=4)\n",
        "\n",
        "\n",
        "# Entrenar el proyecto\n",
        "!deepdanbooru train-project {project_folder}\n",
        "\n",
        "print('La carpeta donde segurdaron tus chekpoints es la siguiente: /content/DeepDanbooru/my_project/checkpoints')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!deepdanbooru evaluate /content/drive/MyDrive/lora_training/datasets/kythe/0d50e3283f08.jpeg --project-path {project_folder} --allow-folder"
      ],
      "metadata": {
        "id": "FLsdbjpbdG70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Tutorial de Hiperparametros\n",
        "\n",
        "print(\"project_data['image_width'] y project_data['image_height']: Establecen el ancho y alto de las imágenes que se utilizarán durante el entrenamiento y evaluación del modelo. Estos valores se establecen en 256 en el ejemplo.\")\n",
        "\n",
        "print(\"project_data['database_path']: Especifica la ruta del archivo de base de datos SQLite que contiene la información de las imágenes y sus etiquetas. En este caso, se establece como 'my_dataset/new-dataset.sqlite', lo que indica que el archivo de base de datos se encuentra en la carpeta 'my_dataset' y se llama 'new-dataset.sqlite'.\")\n",
        "\n",
        "print(\"project_data['minimum_tag_count']: Define el recuento mínimo de etiquetas requerido para que una imagen sea considerada en el entrenamiento. Las imágenes que no cumplan con este requisito se ignorarán. En este caso, se establece en 10.\")\n",
        "\n",
        "print(\"project_data['model']: Especifica el modelo que se utilizará para el entrenamiento y evaluación. En el ejemplo se utiliza el modelo 'resnet_custom_v3'.\")\n",
        "\n",
        "print(\"project_data['minibatch_size']: Establece el tamaño del minibatch utilizado durante el entrenamiento. Un minibatch es un subconjunto de muestras utilizado para calcular los gradientes y actualizar los pesos del modelo. En este caso, se establece en 64.\")\n",
        "\n",
        "print(\"project_data['epoch_count']: Define la cantidad de epochs (iteraciones completas a través del conjunto de datos) que se realizarán durante el entrenamiento. En el ejemplo se establece en 20.\")\n",
        "\n",
        "print(\"project_data['export_model_per_epoch']: Especifica la frecuencia con la que se exportará el modelo durante el entrenamiento. En este caso, se exportará el modelo cada 5 epochs.\")\n",
        "\n",
        "print(\"project_data['checkpoint_frequency_mb']: Define la frecuencia con la que se guardará un punto de control (checkpoint) del modelo durante el entrenamiento. En el ejemplo, se guarda un punto de control cada 100 minibatches.\")\n",
        "\n",
        "print(\"project_data['console_logging_frequency_mb']: Establece la frecuencia con la que se mostrarán los registros de progreso en la consola durante el entrenamiento. En este caso, se mostrarán los registros cada 5 minibatches.\")\n",
        "\n",
        "print(\"project_data['loss']: Especifica la función de pérdida que se utilizará durante el entrenamiento. En el ejemplo se utiliza la pérdida 'categorical_crossentropy', que es comúnmente utilizada en problemas de clasificación.\")\n",
        "\n",
        "print(\"project_data['optimizer']: Define el optimizador que se utilizará para ajustar los pesos del modelo durante el entrenamiento. En el ejemplo se utiliza el optimizador 'sgd', que representa el descenso de gradiente estocástico.\")\n",
        "\n",
        "print(\"project_data['learning_rate']: Establece la tasa de aprendizaje del optimizador. Esta tasa determina qué tan rápido se actualizarán los pesos del modelo durante el entrenamiento. En el ejemplo se establece en 0.01.\")\n",
        "\n",
        "print(\"project_data['rotation_range'], project_data['scale_range'] y project_data['shift_range']: Estos parámetros definen los rangos de rotación, escala y desplazamiento horizontal y vertical aplicados a las imágenes durante el entrenamiento. En el ejemplo se utilizan rangos específicos.\")\n",
        "\n",
        "print(\"project_data['mixed_precision']: Indica si se utilizará la precisión mixta durante el entrenamiento. La precisión mixta es una técnica que utiliza operaciones en punto flotante de menor precisión para acelerar el entrenamiento. En este caso, se establece en True para utilizar la precisión mixta.\")\n",
        "\n",
        "\n",
        "print('''\n",
        "{EJEMPLO BASE:\n",
        "    \"image_width\": 299,\n",
        "    \"image_height\": 299,\n",
        "    \"database_path\": \"my_dataset/my-dataset.sqlite\",\n",
        "    \"minimum_tag_count\": 20,\n",
        "    \"model\": \"resnet_custom_v2\",\n",
        "    \"minibatch_size\": 32,\n",
        "    \"epoch_count\": 10,\n",
        "    \"export_model_per_epoch\": 10,\n",
        "    \"checkpoint_frequency_mb\": 200,\n",
        "    \"console_logging_frequency_mb\": 10,\n",
        "    \"loss\": \"binary_crossentropy\",\n",
        "    \"optimizer\": \"adam\",\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"rotation_range\": [\n",
        "        0.0,\n",
        "        360.0\n",
        "    ],\n",
        "    \"scale_range\": [\n",
        "        0.9,\n",
        "        1.1\n",
        "    ],\n",
        "    \"shift_range\": [\n",
        "        -0.1,\n",
        "        0.1\n",
        "    ],\n",
        "    \"mixed_precision\": false\n",
        "}\n",
        "''')\n",
        "\n",
        "\n",
        "print(\"Para mas informacion consultar el paper : https://github.com/KichangKim/DeepDanbooru\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "iXjC6IxET5O2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}